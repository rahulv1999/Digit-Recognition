{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plot\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ndf1 = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"t = np.array(df.iloc[6,1:])\nnp.reshape(t,(28,28))\nprint(t,df['label'][6])\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop('label',axis=1), df['label'], test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train = np.array(X_train)\nX_train = np.array_split(X_train, len(X_train))\nfor t in range(len(X_train)):\n    X_train[t] = np.reshape(X_train[t], (28,28))\nX_train = np.expand_dims(X_train,-1)\nnp.shape(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.array(X_test)\nX_test = np.array_split(X_test, len(X_test))\nfor t in range(len(X_test)):\n    X_test[t] = np.reshape(X_test[t], (28,28))\nX_test = np.expand_dims(X_test,-1)\nnp.shape(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tgen = ImageDataGenerator( rescale=1./255,\n      rotation_range=10,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.01,\n      zoom_range=0.2,\n      horizontal_flip=False,\n      fill_mode='nearest'\n                                  )\nvgen = ImageDataGenerator( rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.01,\n      zoom_range=0.2,\n      horizontal_flip=False,\n      fill_mode='nearest'\n                                  )\n\nbatchSize = 128\ntrain_generator = tgen.flow(X_train,y_train,batch_size=batchSize)\n\nval_generator = vgen.flow(X_test, y_test,batch_size=batchSize)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ad  = tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nad2 =tf.keras.optimizers.Adam(lr =0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),input_shape = (28,28,1), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.Conv2D(64,(3,3), activation = 'relu',padding = 'Same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(256, activation = 'relu'),\n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.Dense(256, activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.3),\n    tf.keras.layers.Dense(10, activation = 'softmax')\n])\n    \n    model.compile(optimizer = ad, metrics = ['accuracy'], loss = 'sparse_categorical_crossentropy')\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"call_back = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, restore_best_weights=True)\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n                                              factor=0.25,\n                                              verbose=2,\n                                              patience=2,\n                                              min_lr=0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            if(logs.get('val_accuracy')>0.99):\n                print(\"Reached 99% val_accuracy so cancelling training!\")\n                self.model.stop_training = True\n                \n\ncallbacks = myCallback()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,verbose=1,epochs =100,validation_data = val_generator, callbacks = [callbacks,reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\nimport random \nk = np.array(X_train)\nt = k[random.randint(0,100)]\nt = np.reshape(t,(28,28))\n#t = np.expand_dims(t,-1)\ng = plot.imshow(t,cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nlayers_outputs = [layer.output for layer in model.layers[:20]]\nactivation_model = models.Model(inputs=model.input, outputs=layers_outputs) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[9].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=random.randint(0,100)\nimg_tensor = X_train[k]\nimg_tensor = np.expand_dims(img_tensor,0)\nactivations = activation_model.predict(img_tensor) \nn =17\nt = np.reshape(X_train[k],(28,28))\n#fig, axs = plot.subplots(n+1,1)\nplot.matshow(t, cmap='gray')\nfor h in range(n):\n    first_layer_activation = activations[h]\n    print(first_layer_activation.shape)\n    plot.matshow(first_layer_activation[0, :, :, 4], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.lineplot(history.epoch[6:],history.history['accuracy'][6:],label = 'accuracy')\ng.set(xlabel = 'epoc',ylabel  = 'acc')\nsns.lineplot(history.epoch[6:],history.history['val_accuracy'][6:], label = 'val_accuracy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.lineplot(history.epoch[6:],history.history['loss'][6:],label = 'loss')\ng.set(xlabel = 'epoc',ylabel  = 'loss')\nsns.lineplot(history.epoch[6:],history.history['val_loss'][6:], label = 'val_loss')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df1 = df1/255.0\nX_test = df1\nX_test = np.array(X_test)\nX_test = np.array_split(X_test, len(X_test))\nfor t in range(len(X_test)):\n    X_test[t] = np.reshape(X_test[t], (28,28))\nX_test = np.expand_dims(X_test,-1)\n\nk = model.predict(X_test)\n\nk = np.argmax(k,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\nnp.size(k)\nsample['Label'] = k\nsample.to_csv('sol.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}